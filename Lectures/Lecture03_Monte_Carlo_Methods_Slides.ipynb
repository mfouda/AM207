{
 "metadata": {
  "celltoolbar": "Slideshow",
  "name": "",
  "signature": "sha256:963b5fcbe040f0518b351436466157336e5c3519a9f5da436864e219c12a9912"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Lecture 3: Basic Monte Carlo - Integration, sampling and error estimation\n",
      "AM207: Verena Kaynig-Fittkau,and Pavlos Protopapas, Harvard University\n"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "# Announcements\n",
      "\n",
      "- Please sign up for Piazza\n",
      "- Book recommendations:\n",
      "    - Machine Learning: a Probabilistic Perspective by Kevin Patrick Murphy\n",
      "    - Monte Carlo Streategies in Scientific Computing by Jun S. Liu (available as download via Harvard Library)\n",
      "    - Monte Carlo Statistical Methods by Christian P. Robert and George Casella (available as download via Harvard Library)\n",
      "    \n",
      "- Office hours are announced on Piazza\n",
      "- Staff email is am207@gmail.com\n",
      "- Verena's office hours now are in NW B164, time stays Tuesday 2-3 pm.\n",
      "- For extension school: dropbox link on homepage is fixed.\n",
      "- For all: don't forget to submit your homework\n",
      "    "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "import numpy as np\n",
      "from scipy import stats\n",
      "from scipy.stats import norm\n",
      "import matplotlib.pyplot as plt\n",
      "import seaborn as sns\n",
      "sns.set_style('white')\n",
      "sns.set_context('paper')"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "## Estimate the area of a unit circle"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#area of the bounding box\n",
      "box_area = 4.0    \n",
      "\n",
      "#number of samples\n",
      "N_total = 100000.0 \n",
      "\n",
      "#drawing random points uniform between -1 and 1\n",
      "X = np.random.uniform(low=-1, high=1, size=N_total)  \n",
      "Y = np.random.uniform(low=-1, high=1, size=N_total)   \n",
      "\n",
      "# calculate the distance of the point from the center \n",
      "distance = np.sqrt(X**2+Y**2);  \n",
      " \n",
      "# check if point is inside the circle    \n",
      "is_point_inside = distance<1.0\n",
      "\n",
      "# sum up the hits inside the circle\n",
      "N_inside=np.sum(is_point_inside)\n",
      "\n",
      "# estimate the circle area\n",
      "circle_area = box_area * N_inside/N_total\n",
      "\n",
      "# some nice visualization\n",
      "plt.scatter(X,Y, c=is_point_inside, s=5.0, edgecolors='none', cmap=plt.cm.Paired)  \n",
      "plt.axis('equal')\n",
      "\n",
      "# text output\n",
      "print \"Area of the circle = \", circle_area\n",
      "print \"pi = \", np.pi"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Crude Monte Carlo \n",
      "**Calculate the integral $ I= \\int_{2}^{3} [x^2 + 4 \\, x \\,\\sin(x)] \\, dx. $**\n",
      "\n",
      "**For testing we can use the anti-derivative $ \\frac{x^3}{3} + 4\\sin(x) -4x\\cos(x). $ **\n",
      "\n",
      "To solve this using MC, we draw $N$ random numbers from 2 to 3 and then take the average of all the values $f(x)=x^2 + 4 \\, x \\,\\sin(x)$ and normalized over the volume; in this case the volume is 1 (3-2=1). "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# define f(x) for our integral\n",
      "def f(x):\n",
      "    return x**2 + 4*x*np.sin(x) \n",
      "\n",
      "# and the anti-derivative for testing\n",
      "def anti_derivative_f(x): \n",
      "    return x**3/3.0+4.0*np.sin(x) - 4.0*x*np.cos(x) "
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# upper and lower limits:\n",
      "a = 2;    \n",
      "b = 3; \n",
      "\n",
      "# use N draws \n",
      "N= 10000.0\n",
      "\n",
      "#1. N values uniformly drawn from a to b \n",
      "X = np.random.uniform(low=a, high=b, size=N) \n",
      "\n",
      "#2. Compute f(X)\n",
      "Y = f(X)   \n",
      "# and the average\n",
      "f_average = np.sum(Y)/ N\n",
      "\n",
      "#3. estimate value of integral\n",
      "estimate = (b-a) * f_average;\n",
      "\n",
      "#we compute the exact value for testing\n",
      "exact_val = anti_derivative_f(b) - anti_derivative_f(a)\n",
      "\n",
      "print \"Monte Carlo estimate = \",estimate\n",
      "print \"Exact value = \", exact_val"
     ],
     "language": "python",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Mutlidimensional example:\n",
      "\n",
      "**Calculate the integral $I=\\int \\int f(x, y) dx dy$ **\n",
      "\n",
      "where $f(x,y) = x^2 +y^2$ \n",
      "\n",
      "over the region de\ufb01ned by the condition $x^2 +y^2 \u2264 1$. \n",
      "\n",
      "The steps are the same as above, but we need an additional check that the region condition is fulfilled by our random samples."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "#define our f(x,y)\n",
      "f_circle = lambda x,y: x**2 + y**2\n",
      "\n",
      "# use N draws \n",
      "N= 10000\n",
      "\n",
      "#sample X and Y\n",
      "X= np.random.uniform(low=-1, high=1, size=N) \n",
      "Y= np.random.uniform(low=-1, high=1, size=N) \n",
      "\n",
      "# calculate f(x) \n",
      "f_value = f_circle(X, Y)  \n",
      "\n",
      "# reject all samples that do not satisfy our region condition\n",
      "N = np.sum(f_value<1) \n",
      "\n",
      "f_average = np.sum(f_value[f_value<1]) / N\n",
      "\n",
      "print \"Monte Carlo estimate = \", np.pi*f_average\n",
      "print \"Exact value\", np.pi/2.0"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Error estimate\n",
      "\n",
      "How does the accuracy depends on the number of points(samples)? Lets try the same 1-D integral $ I= \\int_{2}^{3} [x^2 + 4 \\, x \\,\\sin(x)] \\, dx $ as a function of the number of points. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# space to save estimates for different N\n",
      "estimates = np.zeros(1000)\n",
      "# upper and lower limits:\n",
      "a = 2;    \n",
      "b = 3; \n",
      "\n",
      "exactval= anti_derivative_f(b)-anti_derivative_f(a)\n",
      "\n",
      "for N in np.arange(0,1000):\n",
      "    # N values uniformly drawn from a to b \n",
      "    X = np.random.uniform(low=a, high=b, size=N) \n",
      "    Y =f(X)   # calculate f(x) \n",
      "    estimates[N]= (b-a) * np.sum(Y)/ N;\n",
      "    \n",
      "errors = np.abs(estimates - exactval)\n",
      "    \n",
      "plot_points = np.linspace(0,1000,1000)   \n",
      "\n",
      "plt.plot(plot_points, errors)\n",
      "plt.plot(plot_points, 1/np.sqrt(plot_points), 'r')\n",
      "\n",
      "plt.xlabel(\"N\")\n",
      "plt.ylabel(\"Error\")\n",
      "plt.ylim(0,0.2)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "Our errors follow a normal distribution, and the variance of this distribution can be seen by plotting the histogram:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# multiple MC estimations\n",
      "m=1000\n",
      "N=1000\n",
      "\n",
      "estimates = np.zeros(m)\n",
      "\n",
      "\n",
      "for i in np.arange(0,m):    \n",
      "    X = np.random.uniform(low=a, high=b, size=N) # N values uniformly drawn from a to b \n",
      "    Y =f(X)   # calculate f(x)\n",
      "\n",
      "    estimates[i]= (b-a) * np.sum(Y)/ N;\n",
      "    \n",
      "    \n",
      "plt.hist(estimates)\n",
      "plt.xlabel(\"Estimate\")\n",
      "print \"Mean: \", np.mean(estimates)\n",
      "print \"Standard deviation: \", np.std(estimates)\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Importance sampling: \n",
      "\n",
      "**Calculate $\\int_{0}^{\\pi} \\sin(x) \\, x \\, dx $**\n",
      "\n",
      "The function has a shape that is similar to Gaussian and therefore we choose here a Gaussian as importance sampling distribution. \n"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# parameters for our normal distribution\n",
      "# that we want to sample from\n",
      "mu = 2;\n",
      "sig = 0.7\n",
      "\n",
      "f = lambda x: np.sin(x)*x\n",
      "anti_derivative_f = lambda x: np.sin(x)-x*np.cos(x)\n",
      "p = lambda x: (1/np.sqrt(2*np.pi*sig**2))*np.exp(-(x-mu)**2/(2.0*sig**2))\n",
      "normfun = lambda x:  norm.cdf(x-mu, scale=sig)\n",
      "\n",
      "# range of integration\n",
      "xmin =0\n",
      "xmax = np.pi\n",
      "\n",
      "# Number of draws \n",
      "N = 1000\n",
      "\n",
      "# plot the functions\n",
      "x=np.linspace(xmin, xmax, 1000)\n",
      "plt.subplot(1,2,1)\n",
      "plt.plot(x, f(x), 'b', label=u'Original  $x\\sin(x)$')\n",
      "plt.plot( x, p(x), 'r', label=u'Importance Sampling Function: Normal')\n",
      "plt.xlabel('x')\n",
      "plt.ylim(0,2.5)\n",
      "plt.legend()\n",
      "\n",
      "# =============================================\n",
      "# EXACT SOLUTION \n",
      "# =============================================\n",
      "Iexact = anti_derivative_f(xmax)-anti_derivative_f(xmin)\n",
      "\n",
      "# ============================================\n",
      "# VANILLA MONTE CARLO \n",
      "# ============================================\n",
      "Ivmc = np.zeros(1000)\n",
      "for k in np.arange(0,1000):\n",
      "    x = np.random.uniform(low=xmin, high=xmax, size=N)\n",
      "    Ivmc[k] = (xmax-xmin)*np.mean(f(x))\n",
      "\n",
      "\n",
      "# ============================================\n",
      "# IMPORTANCE SAMPLING \n",
      "# ============================================\n",
      "# CHOOSE Gaussian so it similar to the original function\n",
      "\n",
      "Iis = np.zeros(1000)\n",
      "for k in np.arange(0,1000):\n",
      "    # draw from a normal distribution \n",
      "    xis = mu + sig*np.random.randn(N,1);\n",
      "    # make sure samples are in our range\n",
      "    xis = xis[ (xis<xmax) & (xis>xmin)] ;\n",
      "\n",
      "    # normalization for Gaussian from 0..pi\n",
      "    normal = normfun(np.pi)-normfun(0);\n",
      "    # computing our estimates\n",
      "    Iis[k] = np.mean(f(xis)/p(xis))*normal;\n",
      "\n",
      "\n",
      "plt.subplot(1,2,2)\n",
      "plt.hist(Ivmc, 30, color='b', histtype='step', label=u'Vanilla MC');\n",
      "plt.hist(Iis,30, color='r', histtype='step', label=u'Importance Sampling');\n",
      "plt.ylim(0,140) \n",
      "plt.legend()\n",
      "plt.show()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {
      "slideshow": {
       "slide_type": "slide"
      }
     },
     "source": [
      "### Inverse transform example\n",
      "**Draw from the distribution $f(x) \\sim \\exp{(-x)}$**\n",
      "\n",
      "The following code will produce numbers that follow the $\\exp{(-x)}$ distribution. The figure\n",
      "generated by code below shows the resulting histogram of the generated numbers\n",
      "compared to the actual $\\exp{(-x)}$."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# probability distribution we're trying to calculate\n",
      "p = lambda x: np.exp(-x)\n",
      "\n",
      "# CDF of p\n",
      "CDF = lambda x: 1-np.exp(-x)\n",
      "\n",
      "# invert the CDF\n",
      "invCDF = lambda x: -np.log(1-x)\n",
      "\n",
      "# domain limits\n",
      "xmin = 0 # the lower limit of our domain\n",
      "xmax = 6 # the upper limit of our domain\n",
      "\n",
      "# range limits\n",
      "rmin = CDF(xmin)\n",
      "rmax = CDF(xmax)\n",
      "\n",
      "N = 10000 # the total of samples we wish to generate\n",
      "\n",
      "# generate uniform samples in our range then invert the CDF\n",
      "# to get samples of our target distribution\n",
      "R = np.random.uniform(rmin, rmax, N)\n",
      "X = invCDF(R)\n",
      "\n",
      "# get the histogram info\n",
      "hinfo = np.histogram(X,100)\n",
      "\n",
      "# plot the histogram\n",
      "plt.hist(X,bins=100, label=u'Samples', alpha=0.5);\n",
      "\n",
      "# plot our (normalized) function\n",
      "xvals=np.linspace(xmin, xmax, 1000)\n",
      "plt.plot(xvals, hinfo[0][0]*p(xvals), 'r', label=u'p(x)')\n",
      "\n",
      "# turn on the legend\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Rejection sampling example:\n",
      "The following code produces samples that follow the distribution $P(x)=e^{-x}$ \n",
      "  for $x=[0,10]$ and generates a histogram of the sampled distribution. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "P = lambda x: np.exp(-x)\n",
      "\n",
      "# domain limits\n",
      "xmin = 0 # the lower limit of our domain\n",
      "xmax = 10 # the upper limit of our domain\n",
      "\n",
      "# range limit (supremum) for y\n",
      "ymax = 1\n",
      "\n",
      "N = 10000 # the total of samples we wish to generate\n",
      "accepted = 0 # the number of accepted samples\n",
      "samples = np.zeros(N)\n",
      "count = 0 # the total count of proposals\n",
      "\n",
      "# generation loop\n",
      "while (accepted < N):\n",
      "    \n",
      "    # pick a uniform number on [xmin, xmax) (e.g. 0...10)\n",
      "    x = np.random.uniform(xmin, xmax)\n",
      "    \n",
      "    # pick a uniform number on [0, ymax)\n",
      "    y = np.random.uniform(0,ymax)\n",
      "    \n",
      "    # Do the accept/reject comparison\n",
      "    if y < P(x):\n",
      "        samples[accepted] = x\n",
      "        accepted += 1\n",
      "    \n",
      "    count +=1\n",
      "    \n",
      "print \"Total samples drawn: \",count\n",
      "print \"Number of accepted samples: \", accepted\n",
      "\n",
      "# get the histogram info\n",
      "hinfo = np.histogram(samples,30)\n",
      "\n",
      "# plot the histogram\n",
      "plt.hist(samples,bins=30, label=u'Samples', alpha=0.5, normed=True);\n",
      "\n",
      "# plot our (normalized) function\n",
      "xvals=np.linspace(xmin, xmax, 1000)\n",
      "plt.plot(xvals, P(xvals), 'r', label=u'P(x)')\n",
      "\n",
      "# turn on the legend\n",
      "plt.legend()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "** The same on steroids **"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "p = lambda x: np.exp(-x)  # our distribution\n",
      "g = lambda x: 1/(x+1)  # our proposal pdf (we're thus choosing M to be 1)\n",
      "invCDFg = lambda x: np.log(x +1) # generates our proposal using inverse sampling\n",
      "\n",
      "# domain limits\n",
      "xmin = 0 # the lower limit of our domain\n",
      "xmax = 10 # the upper limit of our domain\n",
      "\n",
      "# range limits for inverse sampling\n",
      "umin = invCDFg(xmin)\n",
      "umax = invCDFg(xmax)\n",
      "\n",
      "N = 10000 # the total of samples we wish to generate\n",
      "accepted = 0 # the number of accepted samples\n",
      "samples = np.zeros(N)\n",
      "count = 0 # the total count of proposals\n",
      "\n",
      "# generation loop\n",
      "while (accepted < N):\n",
      "    \n",
      "    # Sample from g using inverse sampling\n",
      "    u = np.random.uniform(umin, umax)\n",
      "    xproposal = np.exp(u) - 1\n",
      "    \n",
      "    # pick a uniform number on [0, 1)\n",
      "    y = np.random.uniform(0,1)\n",
      "    \n",
      "    # Do the accept/reject comparison\n",
      "    if y < p(xproposal)/g(xproposal):\n",
      "        samples[accepted] = xproposal\n",
      "        accepted += 1\n",
      "    \n",
      "    count +=1\n",
      "    \n",
      "print count, accepted\n",
      "\n",
      "# get the histogram info\n",
      "hinfo = np.histogram(samples,50)\n",
      "\n",
      "# plot the histogram\n",
      "plt.hist(samples,bins=50, label=u'Samples', alpha=0.5, normed=True);\n",
      "\n",
      "# plot our (normalized) function\n",
      "xvals=np.linspace(xmin, xmax, 1000)\n",
      "plt.plot(xvals, p(xvals), 'r', label=u'p(x)')\n",
      "plt.plot(xvals, g(xvals), 'g', label=u'g(x)')\n",
      "\n",
      "# turn on the legend\n",
      "plt.legend()\n"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}